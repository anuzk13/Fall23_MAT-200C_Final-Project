<!doctype html><html><head><title>NERF Paper</title><base href="./"><meta id="root-path" root-path="./"><link rel="icon" sizes="96x96" href="https://publish-01.obsidian.md/access/f786db9fac45774fa4f0d8112e232d67/favicon-96x96.png"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=yes,minimum-scale=1,maximum-scale=5"><meta charset="UTF-8"><link rel="stylesheet" href="lib/styles/obsidian-styles.css"><link rel="stylesheet" href="lib/styles/theme.css"><link rel="stylesheet" href="lib/styles/plugin-styles.css"><link rel="stylesheet" href="lib/styles/snippets.css"><link rel="stylesheet" href="lib/styles/generated-styles.css"><style></style><script type="module" src="lib/scripts/graph_view.js"></script><script src="lib/scripts/graph_wasm.js"></script><script src="lib/scripts/tinycolor.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/pixi.js/7.2.4/pixi.min.js" integrity="sha512-Ch/O6kL8BqUwAfCF7Ie5SX1Hin+BJgYH4pNjRqXdTEqMsis1TUYg+j6nnI9uduPjGaj7DN4UKCZgpvoExt6dkw==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><script src="lib/scripts/webpage.js"></script><script src="lib/scripts/generated.js"></script></head><body class="show-inline-title theme-light loading"><div class="webpage-container"><div class="sidebar-left sidebar"><div class="sidebar-container"><div class="sidebar-sizer"><div class="sidebar-content-positioner"><div class="sidebar-content"><div><label class="theme-toggle-container" for="theme_toggle"><input class="theme-toggle-input" type="checkbox" id="theme_toggle"><div class="toggle-background"></div></label></div><div class="tree-container file-tree mod-nav-indicator" data-depth="0"><div class="tree-header"><span class="sidebar-section-header">Vault</span><button class="clickable-icon collapse-tree-button is-collapsed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></svg></button></div><div class="tree-scroll-area"><div class="tree-item mod-tree-folder mod-collapsible is-collapsed" data-depth="1"><div class="tree-item-contents"><a class="internal-link tree-item-link"><div class="tree-item-icon collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><span class="tree-item-title">images</span></a></div><div class="tree-item-children" style="display:none"><div class="tree-item mod-tree-file" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="images/ezgif-3-616785f8ff.gif"><span class="tree-item-title">ezgif-3-616785f8ff</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="images/ezgif-3-85421be3e1.gif"><span class="tree-item-title">ezgif-3-85421be3e1</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="images/ezgif-3-8c7bc2777f.gif"><span class="tree-item-title">ezgif-3-8c7bc2777f</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="images/pasted-image-20231024084616.png"><span class="tree-item-title">Pasted image 20231024084616</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="images/pasted-image-20231113205713.png"><span class="tree-item-title">Pasted image 20231113205713</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="images/pasted-image-20231113212602.png"><span class="tree-item-title">Pasted image 20231113212602</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="images/pasted-image-20231113213137.png"><span class="tree-item-title">Pasted image 20231113213137</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="images/pasted-image-20231113213804.png"><span class="tree-item-title">Pasted image 20231113213804</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="images/pasted-image-20231113214357.png"><span class="tree-item-title">Pasted image 20231113214357</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="images/pasted-image-20231113214512.png"><span class="tree-item-title">Pasted image 20231113214512</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="images/pasted-image-20231113215201.png"><span class="tree-item-title">Pasted image 20231113215201</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="images/pasted-image-20231113215918.png"><span class="tree-item-title">Pasted image 20231113215918</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="images/pasted-image-20231116112026.png"><span class="tree-item-title">Pasted image 20231116112026</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="images/pasted-image-20231116112046.png"><span class="tree-item-title">Pasted image 20231116112046</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="images/pasted-image-20231130162005.png"><span class="tree-item-title">Pasted image 20231130162005</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="images/pasted-image-20231130171636.png"><span class="tree-item-title">Pasted image 20231130171636</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="images/pasted-image-20231204135536.png"><span class="tree-item-title">Pasted image 20231204135536</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="images/pasted-image-20231204140332.png"><span class="tree-item-title">Pasted image 20231204140332</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="images/pasted-image-20231204141622.png"><span class="tree-item-title">Pasted image 20231204141622</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="images/pasted-image-20231206141453.png"><span class="tree-item-title">Pasted image 20231206141453</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="images/pasted-image-20231206142320.png"><span class="tree-item-title">Pasted image 20231206142320</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="images/pasted-image-20231206143247.png"><span class="tree-item-title">Pasted image 20231206143247</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="images/pasted-image-20231206143404.png"><span class="tree-item-title">Pasted image 20231206143404</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="images/pasted-image-20231206143407.png"><span class="tree-item-title">Pasted image 20231206143407</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="images/pasted-image-20231206143516.png"><span class="tree-item-title">Pasted image 20231206143516</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="images/pasted-image-20231206144226.png"><span class="tree-item-title">Pasted image 20231206144226</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="images/pasted-image-20231206155038.png"><span class="tree-item-title">Pasted image 20231206155038</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="images/pasted-image-20231206155930.png"><span class="tree-item-title">Pasted image 20231206155930</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="images/pasted-image-20231206160002.png"><span class="tree-item-title">Pasted image 20231206160002</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="images/pasted-image-20231207112824.png"><span class="tree-item-title">Pasted image 20231207112824</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="images/pasted-image-20231210171854.png"><span class="tree-item-title">Pasted image 20231210171854</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="images/pasted-image-20231210183525.png"><span class="tree-item-title">Pasted image 20231210183525</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="images/pasted-image-20231212133934.png"><span class="tree-item-title">Pasted image 20231212133934</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="images/pasted-image-20231212133937.png"><span class="tree-item-title">Pasted image 20231212133937</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="images/pasted-image-20231213204850.png"><span class="tree-item-title">Pasted image 20231213204850</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="images/pasted-image-20231213210019.png"><span class="tree-item-title">Pasted image 20231213210019</span></a></div><div class="tree-item-children"></div></div></div></div><div class="tree-item mod-tree-file" data-depth="1"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="gs_paper.html"><span class="tree-item-title">GS_paper</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="1"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="index.html"><span class="tree-item-title">index</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="1"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="nerf-paper.html"><span class="tree-item-title">NERF Paper</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="1"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="playing.html"><span class="tree-item-title">playing</span></a></div><div class="tree-item-children"></div></div></div></div></div></div></div></div><div class="sidebar-gutter"><div class="clickable-icon sidebar-collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><path d="M21 3H3C1.89543 3 1 3.89543 1 5V19C1 20.1046 1.89543 21 3 21H21C22.1046 21 23 20.1046 23 19V5C23 3.89543 22.1046 3 21 3Z"></path><path d="M10 4V20"></path><path d="M4 7H7"></path><path d="M4 10H7"></path><path d="M4 13H7"></path></svg></div></div></div><div class="document-container show"><div class="markdown-preview-view markdown-rendered node-insert-event is-readable-line-width allow-fold-headings show-indentation-guide allow-fold-lists show-properties" style="tab-size:4"><style id="MJX-CHTML-styles">mjx-container[jax=CHTML]{line-height:0}mjx-container [space="1"]{margin-left:.111em}mjx-container [space="2"]{margin-left:.167em}mjx-container [space="3"]{margin-left:.222em}mjx-container [space="4"]{margin-left:.278em}mjx-container [space="5"]{margin-left:.333em}mjx-container [rspace="1"]{margin-right:.111em}mjx-container [rspace="2"]{margin-right:.167em}mjx-container [rspace="3"]{margin-right:.222em}mjx-container [rspace="4"]{margin-right:.278em}mjx-container [rspace="5"]{margin-right:.333em}mjx-container [size="s"]{font-size:70.7%}mjx-container [size=ss]{font-size:50%}mjx-container [size=Tn]{font-size:60%}mjx-container [size=sm]{font-size:85%}mjx-container [size=lg]{font-size:120%}mjx-container [size=Lg]{font-size:144%}mjx-container [size=LG]{font-size:173%}mjx-container [size=hg]{font-size:207%}mjx-container [size=HG]{font-size:249%}mjx-container [width=full]{width:100%}mjx-box{display:inline-block}mjx-block{display:block}mjx-itable{display:inline-table}mjx-row{display:table-row}mjx-row>*{display:table-cell}mjx-mtext{display:inline-block}mjx-mstyle{display:inline-block}mjx-merror{display:inline-block;color:red;background-color:#ff0}mjx-mphantom{visibility:hidden}mjx-assistive-mml{top:0;left:0;clip:rect(1px,1px,1px,1px);user-select:none;position:absolute!important;padding:1px 0 0!important;border:0!important;display:block!important;width:auto!important;overflow:hidden!important}mjx-assistive-mml[display=block]{width:100%!important}mjx-math{display:inline-block;text-align:left;line-height:0;text-indent:0;font-style:normal;font-weight:400;font-size:100%;letter-spacing:normal;border-collapse:collapse;overflow-wrap:normal;word-spacing:normal;white-space:nowrap;direction:ltr;padding:1px 0}mjx-container[jax=CHTML][display=true]{display:block;text-align:center;margin:1em 0}mjx-container[jax=CHTML][display=true][width=full]{display:flex}mjx-container[jax=CHTML][display=true] mjx-math{padding:0}mjx-container[jax=CHTML][justify=left]{text-align:left}mjx-container[jax=CHTML][justify=right]{text-align:right}mjx-mi{display:inline-block;text-align:left}mjx-c{display:inline-block}mjx-utext{display:inline-block;padding:.75em 0 .2em}mjx-mo{display:inline-block;text-align:left}mjx-stretchy-h{display:inline-table;width:100%}mjx-stretchy-h>*{display:table-cell;width:0}mjx-stretchy-h>*>mjx-c{display:inline-block;transform:scaleX(1)}mjx-stretchy-h>*>mjx-c::before{display:inline-block;width:initial}mjx-stretchy-h>mjx-ext{overflow:clip visible;width:100%}mjx-stretchy-h>mjx-ext>mjx-c::before{transform:scaleX(500)}mjx-stretchy-h>mjx-ext>mjx-c{width:0}mjx-stretchy-h>mjx-beg>mjx-c{margin-right:-.1em}mjx-stretchy-h>mjx-end>mjx-c{margin-left:-.1em}mjx-stretchy-v{display:inline-block}mjx-stretchy-v>*{display:block}mjx-stretchy-v>mjx-beg{height:0}mjx-stretchy-v>mjx-end>mjx-c{display:block}mjx-stretchy-v>*>mjx-c{transform:scaleY(1);transform-origin:left center;overflow:hidden}mjx-stretchy-v>mjx-ext{display:block;height:100%;box-sizing:border-box;border:0 solid transparent;overflow:visible clip}mjx-stretchy-v>mjx-ext>mjx-c::before{width:initial;box-sizing:border-box}mjx-stretchy-v>mjx-ext>mjx-c{transform:scaleY(500) translateY(.075em);overflow:visible}mjx-mark{display:inline-block;height:0}mjx-msup{display:inline-block;text-align:left}mjx-texatom{display:inline-block;text-align:left}mjx-mfrac{display:inline-block;text-align:left}mjx-frac{display:inline-block;vertical-align:.17em;padding:0 .22em}mjx-frac[type="d"]{vertical-align:.04em}mjx-frac[delims]{padding:0 .1em}mjx-frac[atop]{padding:0 .12em}mjx-frac[atop][delims]{padding:0}mjx-dtable{display:inline-table;width:100%}mjx-dtable>*{font-size:2000%}mjx-dbox{display:block;font-size:5%}mjx-num{display:block;text-align:center}mjx-den{display:block;text-align:center}mjx-mfrac[bevelled]>mjx-num{display:inline-block}mjx-mfrac[bevelled]>mjx-den{display:inline-block}mjx-den[align=right],mjx-num[align=right]{text-align:right}mjx-den[align=left],mjx-num[align=left]{text-align:left}mjx-nstrut{display:inline-block;height:.054em;width:0;vertical-align:-.054em}mjx-nstrut[type="d"]{height:.217em;vertical-align:-.217em}mjx-dstrut{display:inline-block;height:.505em;width:0}mjx-dstrut[type="d"]{height:.726em}mjx-line{display:block;box-sizing:border-box;min-height:1px;height:.06em;border-top:.06em solid;margin:.06em -.1em;overflow:hidden}mjx-line[type="d"]{margin:.18em -.1em}mjx-mn{display:inline-block;text-align:left}mjx-c::before{display:block;width:0}.MJX-TEX{font-family:MJXZERO,MJXTEX}.TEX-B{font-family:MJXZERO,MJXTEX-B}.TEX-I{font-family:MJXZERO,MJXTEX-I}.TEX-MI{font-family:MJXZERO,MJXTEX-MI}.TEX-BI{font-family:MJXZERO,MJXTEX-BI}.TEX-S1{font-family:MJXZERO,MJXTEX-S1}.TEX-S2{font-family:MJXZERO,MJXTEX-S2}.TEX-S3{font-family:MJXZERO,MJXTEX-S3}.TEX-S4{font-family:MJXZERO,MJXTEX-S4}.TEX-A{font-family:MJXZERO,MJXTEX-A}.TEX-C{font-family:MJXZERO,MJXTEX-C}.TEX-CB{font-family:MJXZERO,MJXTEX-CB}.TEX-FR{font-family:MJXZERO,MJXTEX-FR}.TEX-FRB{font-family:MJXZERO,MJXTEX-FRB}.TEX-SS{font-family:MJXZERO,MJXTEX-SS}.TEX-SSB{font-family:MJXZERO,MJXTEX-SSB}.TEX-SSI{font-family:MJXZERO,MJXTEX-SSI}.TEX-SC{font-family:MJXZERO,MJXTEX-SC}.TEX-T{font-family:MJXZERO,MJXTEX-T}.TEX-V{font-family:MJXZERO,MJXTEX-V}.TEX-VB{font-family:MJXZERO,MJXTEX-VB}mjx-stretchy-h mjx-c,mjx-stretchy-v mjx-c{font-family:MJXZERO,MJXTEX-S1,MJXTEX-S4,MJXTEX,MJXTEX-A!important}@font-face{font-family:MJXZERO;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Zero.woff") format("woff")}@font-face{font-family:MJXTEX;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Main-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-B;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Main-Bold.woff") format("woff")}@font-face{font-family:MJXTEX-I;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Math-Italic.woff") format("woff")}@font-face{font-family:MJXTEX-MI;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Main-Italic.woff") format("woff")}@font-face{font-family:MJXTEX-BI;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Math-BoldItalic.woff") format("woff")}@font-face{font-family:MJXTEX-S1;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Size1-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-S2;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Size2-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-S3;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Size3-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-S4;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Size4-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-A;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_AMS-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-C;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Calligraphic-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-CB;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Calligraphic-Bold.woff") format("woff")}@font-face{font-family:MJXTEX-FR;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Fraktur-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-FRB;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Fraktur-Bold.woff") format("woff")}@font-face{font-family:MJXTEX-SS;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_SansSerif-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-SSB;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_SansSerif-Bold.woff") format("woff")}@font-face{font-family:MJXTEX-SSI;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_SansSerif-Italic.woff") format("woff")}@font-face{font-family:MJXTEX-SC;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Script-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-T;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Typewriter-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-V;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Vector-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-VB;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Vector-Bold.woff") format("woff")}mjx-c.mjx-c1D43A.TEX-I::before{padding:.705em .786em .022em 0;content:"G"}mjx-c.mjx-c28::before{padding:.75em .389em .25em 0;content:"("}mjx-c.mjx-c1D465.TEX-I::before{padding:.442em .572em .011em 0;content:"x"}mjx-c.mjx-c29::before{padding:.75em .389em .25em 0;content:")"}mjx-c.mjx-c3D::before{padding:.583em .778em .082em 0;content:"="}mjx-c.mjx-c1D452.TEX-I::before{padding:.442em .466em .011em 0;content:"e"}mjx-c.mjx-c2212::before{padding:.583em .778em .082em 0;content:"−"}mjx-c.mjx-c31::before{padding:.666em .5em 0 0;content:"1"}mjx-c.mjx-c32::before{padding:.666em .5em 0 0;content:"2"}mjx-c.mjx-c1D447.TEX-I::before{padding:.677em .704em 0 0;content:"T"}mjx-c.mjx-c3A3::before{padding:.683em .722em 0 0;content:"Σ"}mjx-c.mjx-c2032::before{padding:.56em .275em 0 0;content:"′"}mjx-c.mjx-c1D409.TEX-B::before{padding:.686em .594em .011em 0;content:"J"}mjx-c.mjx-c1D416.TEX-B::before{padding:.686em 1.189em .007em 0;content:"W"}mjx-c.mjx-c1D6BA.TEX-B::before{padding:.686em .831em 0 0;content:"Σ"}</style><div class="markdown-preview-sizer markdown-preview-section" style="min-height:7810px"><div class="markdown-preview-pusher" style="width:1px;height:.1px;margin-bottom:0"></div><div class="mod-header"><div class="inline-title" data-heading="NERF Paper" id="NERF_Paper" style="display:block">NERF Paper</div></div><div><ul><li data-line="0"><a rel="noopener" class="external-link" href="https://colab.research.google.com/github/bmild/nerf/blob/master/tiny_nerf.ipynb" target="_blank">https://colab.research.google.com/github/bmild/nerf/blob/master/tiny_nerf.ipynb</a></li><li data-line="1"><a data-tooltip-position="top" aria-label="https://www.youtube.com/watch?v=dPWLybp4LL0" rel="noopener" class="external-link" href="https://www.youtube.com/watch?v=dPWLybp4LL0" target="_blank">video</a></li></ul></div><div><p><strong>Conclusion</strong><br>- Nerfs build on volume rendering techniques and combine them with the idea of representing 3d scene as a continuous function (to reduce size) and do some estimations of the volume rendering techniques to make it a differentiable function, and use some other optimizations such as training a coarse and detailed network to optimize ray sampling and also re-encoding the parameters of the network (camera position and orientation) because they found out that when the rendering function maps to high frequency domains of color and shape the network does not perform well...so they do some re-mapping that I don't 100% understand to make it a lower frequency function<br>- To render them on web I need to <a data-tooltip-position="top" aria-label="https://phog.github.io/snerg/" rel="noopener" class="external-link" href="https://phog.github.io/snerg/" target="_blank">bake them</a><br>- It is yet unclear to me what is the relation between Nerfs and Gaussian Splatting but the second seems to be the one available and explored in web versions <a rel="noopener" class="external-link" href="https://github.com/antimatter15/splat" target="_blank">https://github.com/antimatter15/splat</a><br>- <a rel="noopener" class="external-link" href="https://poly.cam/tools/gaussian-splatting" target="_blank">https://poly.cam/tools/gaussian-splatting</a><br>- <a rel="noopener" class="external-link" href="https://twitter.com/antimatter15?lang=en" target="_blank">https://twitter.com/antimatter15?lang=en</a></p></div><div><p><strong>Reading notes</strong></p></div><div><ul><li data-line="0"><p>Intro</p><ul><li data-line="1">“Our method optimizes a deep fully-connected neural network without any convolutional layers (often referred to as a multilayer perceptron or MLP)” (<a data-tooltip-position="top" aria-label="zotero://select/library/items/8FBKWBMU" rel="noopener" class="external-link" href="zotero://select/library/items/8FBKWBMU" target="_blank">Mildenhall et al., 2020, p. 1</a>) (<a data-tooltip-position="top" aria-label="zotero://open-pdf/library/items/JMSMQL9S?page=1&amp;annotation=SA4L2B4Q" rel="noopener" class="external-link" href="zotero://open-pdf/library/items/JMSMQL9S?page=1&amp;annotation=SA4L2B4Q" target="_blank">pdf</a>)</li><li data-line="2">“We represent a static scene as a continuous 5D function that<ul><li data-line="3">outputs the <strong>radiance field (radiance emitted in each direction (θ, φ) at each point (x, y, z) in space)</strong></li><li data-line="4">and a density at each point which acts like a differential opacity controlling how much radiance is accumulated by a ray passing through (x, y, z)” (<a data-tooltip-position="top" aria-label="zotero://select/library/items/8FBKWBMU" rel="noopener" class="external-link" href="zotero://select/library/items/8FBKWBMU" target="_blank">Mildenhall et al., 2020, p. 1</a>) (<a data-tooltip-position="top" aria-label="zotero://open-pdf/library/items/JMSMQL9S?page=1&amp;annotation=N4CY546K" rel="noopener" class="external-link" href="zotero://open-pdf/library/items/JMSMQL9S?page=1&amp;annotation=N4CY546K" target="_blank">pdf</a>)</li></ul></li><li data-line="5">“To render this neural radiance field (NeRF)”:<ul><li data-line="6">“1) march camera rays through the scene to generate a sampled set of 3D points,</li><li data-line="7"><ol start="2"><li data-line="7">use those points and their corresponding 2D viewing directions as input to the neural network to produce an output set of colors and densities, and</li></ol></li><li data-line="8"><ol start="3"><li data-line="8">use classical volume rendering techniques to accumulate those colors and densities into a 2D image.</li></ol></li></ul></li><li data-line="9">Because this process is naturally differentiable, we can use gradient descent to optimize this model by minimizing the error between each observed image and the corresponding views rendered from our representation.</li><li data-line="10">Minimizing this error across multiple views encourages the network to predict a coherent model of the scene by assigning high volume densities and accurate colors to the locations that contain the true underlying scene content.” (<a data-tooltip-position="top" aria-label="zotero://select/library/items/8FBKWBMU" rel="noopener" class="external-link" href="zotero://select/library/items/8FBKWBMU" target="_blank">Mildenhall et al., 2020, p. 2</a>) (<a data-tooltip-position="top" aria-label="zotero://open-pdf/library/items/JMSMQL9S?page=2&amp;annotation=RFFL2G3G" rel="noopener" class="external-link" href="zotero://open-pdf/library/items/JMSMQL9S?page=2&amp;annotation=RFFL2G3G" target="_blank">pdf</a>)</li><li data-line="11">Optimization<ul><li data-line="12">“transforming input 5D coordinates with a positional encoding that enables the MLP to represent higher frequency functions, and we propose a hierarchical sampling procedure to reduce the number of queries required to adequately sample this high-frequency scene representation.” (<a data-tooltip-position="top" aria-label="zotero://select/library/items/8FBKWBMU" rel="noopener" class="external-link" href="zotero://select/library/items/8FBKWBMU" target="_blank">Mildenhall et al., 2020, p. 2</a>) (<a data-tooltip-position="top" aria-label="zotero://open-pdf/library/items/JMSMQL9S?page=2&amp;annotation=J4SNX7J3" rel="noopener" class="external-link" href="zotero://open-pdf/library/items/JMSMQL9S?page=2&amp;annotation=J4SNX7J3" target="_blank">pdf</a>)</li></ul></li></ul></li><li data-line="14"><p>Related work</p><ul><li data-line="15">Neural 3D shape representations<ul><li data-line="16">Continuous functions that represent a 3d scene:<ul><li data-line="17"><div alt="Pasted image 20231113214512" src="images\pasted-image-20231113214512.png" class="internal-embed media-embed image-embed is-loaded"><img alt="Pasted image 20231113214512" src="images\pasted-image-20231113214512.png"></div></li></ul></li><li data-line="18">“A promising recent direction in computer vision is encoding objects and scenes in the weights of an MLP that directly maps from a 3D spatial location to an implicit representation of the shape, such as the signed distance” (<a data-tooltip-position="top" aria-label="zotero://open-pdf/library/items/JMSMQL9S?page=3&amp;annotation=NYIJC6LX" rel="noopener" class="external-link" href="zotero://open-pdf/library/items/JMSMQL9S?page=3&amp;annotation=NYIJC6LX" target="_blank">pdf</a>)<ul><li data-line="19">Implicit representations (SDF)<ul><li data-line="20"><a rel="noopener" class="external-link" href="https://youtu.be/B2BTSKcYqtQ?si=Vr70sa2Ss47uKfJH&amp;t=155" target="_blank">https://youtu.be/B2BTSKcYqtQ?si=Vr70sa2Ss47uKfJH&amp;t=155</a></li><li data-line="21"><a rel="noopener" class="external-link" href="https://alpha.womp.com/projects/442905" target="_blank">https://alpha.womp.com/projects/442905</a></li><li data-line="22"><a rel="noopener" class="external-link" href="https://editor.p5js.org/triplezero/sketches/IeE6fvLY7" target="_blank">https://editor.p5js.org/triplezero/sketches/IeE6fvLY7</a></li></ul></li><li data-line="23">“implicit representation of continuous 3D shapes as level sets by optimizing deep networks that map xyz coordinates to signed distance functions” (<a data-tooltip-position="top" aria-label="zotero://open-pdf/library/items/JMSMQL9S?page=3&amp;annotation=U6DEKZUW" rel="noopener" class="external-link" href="zotero://open-pdf/library/items/JMSMQL9S?page=3&amp;annotation=U6DEKZUW" target="_blank">pdf</a>) -&gt; requires 3D models<ul><li data-line="24"><a rel="noopener" class="external-link" href="http://www.maxjiang.ml/proj/lig" target="_blank">http://www.maxjiang.ml/proj/lig</a></li></ul></li><li data-line="25">These wo</li><li data-line="26">Niemeyer, M., Mescheder, L., Oechsle, M., Geiger, A.: Differentiable volumetric rendering: Learning implicit 3D representations without 3D supervision. In: CVPR (2019)<ul><li data-line="27"><a rel="noopener" class="external-link" href="https://github.com/autonomousvision/differentiable_volumetric_rendering" target="_blank">https://github.com/autonomousvision/differentiable_volumetric_rendering</a></li></ul></li><li data-line="28">Sitzmann, V., Zollhoefer, M., Wetzstein, G.: Scene representation networks: Continuous 3D-structure-aware neural scene representations. In: NeurIPS (2019)<ul><li data-line="29"><a rel="noopener" class="external-link" href="https://github.com/vsitzmann/scene-representation-networks" target="_blank">https://github.com/vsitzmann/scene-representation-networks</a></li></ul></li></ul></li></ul></li><li data-line="30">View synthesis and image-based rendering<ul><li data-line="31">“Given a dense sampling of views, photorealistic novel views can be reconstructed by simple light field sample interpolation techniques [21,5,7].” (<a data-tooltip-position="top" aria-label="zotero://open-pdf/library/items/JMSMQL9S?page=4&amp;annotation=RGDW8IJX" rel="noopener" class="external-link" href="zotero://open-pdf/library/items/JMSMQL9S?page=4&amp;annotation=RGDW8IJX" target="_blank">pdf</a>)<ul><li data-line="32"><a data-tooltip-position="top" aria-label="http://www.cs.cmu.edu/afs/cs/academic/class/16823-s16/www/T2P4.pdf" rel="noopener" class="external-link" href="http://www.cs.cmu.edu/afs/cs/academic/class/16823-s16/www/T2P4.pdf" target="_blank">Light field rendering</a></li></ul></li><li data-line="33">“For novel view synthesis with sparser view sampling, the computer vision and graphics communities have made significant progress by predicting traditional geometry and appearance representations from observed images” (<a data-tooltip-position="top" aria-label="zotero://open-pdf/library/items/JMSMQL9S?page=4&amp;annotation=XWVCYM84" rel="noopener" class="external-link" href="zotero://open-pdf/library/items/JMSMQL9S?page=4&amp;annotation=XWVCYM84" target="_blank">pdf</a>)</li><li data-line="34">mesh-based methods.<ul><li data-line="35">Differentiable rasterizers or pathtracer can directly optimize mesh representations to reproduce a set of input images using gradient descent. this strategy requires a template mesh with fixed topology to be provided</li><li data-line="36"><a data-tooltip-position="top" aria-label="https://github.com/NVIDIAGameWorks/kaolin" rel="noopener" class="external-link" href="https://github.com/NVIDIAGameWorks/kaolin" target="_blank">Kaolin library</a></li><li data-line="37"><a data-tooltip-position="top" aria-label="https://research.nvidia.com/labs/toronto-ai/DIB-R/" rel="noopener" class="external-link" href="https://research.nvidia.com/labs/toronto-ai/DIB-R/" target="_blank">Learning to Predict 3D Objects with an Interpolation-based Differentiable Renderer</a></li><li data-line="38"><a data-tooltip-position="top" aria-label="https://people.csail.mit.edu/tzumao/diffrt/" rel="noopener" class="external-link" href="https://people.csail.mit.edu/tzumao/diffrt/" target="_blank">Differentiable Monte Carlo Ray Tracing through Edge Sampling</a></li></ul></li><li data-line="39">volumetric representations -&gt; discrete volumetric representations like voxel grids or planes<ul><li data-line="40"><a rel="noopener" class="external-link" href="https://stephenlombardi.github.io/projects/neuralvolumes/" target="_blank">https://stephenlombardi.github.io/projects/neuralvolumes/</a></li><li data-line="41"><div alt="Pasted image 20231113213804" src="images\pasted-image-20231113213804.png" class="internal-embed media-embed image-embed is-loaded"><img alt="Pasted image 20231113213804" src="images\pasted-image-20231113213804.png"></div></li><li data-line="42">“used large datasets of multiple scenes to train deep networks that predict a sampled volumetric representation from a set of input images, and then use either alpha-compositing or learned compositing along rays to render novel views at test time.” (<a data-tooltip-position="top" aria-label="zotero://select/library/items/8FBKWBMU" rel="noopener" class="external-link" href="zotero://select/library/items/8FBKWBMU" target="_blank">Mildenhall et al., 2020, p. 4</a>) (<a data-tooltip-position="top" aria-label="zotero://open-pdf/library/items/JMSMQL9S?page=4&amp;annotation=DDFDBT7D" rel="noopener" class="external-link" href="zotero://open-pdf/library/items/JMSMQL9S?page=4&amp;annotation=DDFDBT7D" target="_blank">pdf</a>). “their ability to scale to higher resolution imagery is fundamentally limited by poor time and space complexity due to their discrete sampling” (<a data-tooltip-position="top" aria-label="zotero://select/library/items/8FBKWBMU" rel="noopener" class="external-link" href="zotero://select/library/items/8FBKWBMU" target="_blank">Mildenhall et al., 2020, p. 4</a>) (<a data-tooltip-position="top" aria-label="zotero://open-pdf/library/items/JMSMQL9S?page=4&amp;annotation=E3KVBLA7" rel="noopener" class="external-link" href="zotero://open-pdf/library/items/JMSMQL9S?page=4&amp;annotation=E3KVBLA7" target="_blank">pdf</a>)</li><li data-line="43"><a data-tooltip-position="top" aria-label="https://augmentedperception.github.io/deepview/" rel="noopener" class="external-link" href="https://augmentedperception.github.io/deepview/" target="_blank">DeepView View Synthesis with Learned Gradient Descent</a></li></ul></li></ul></li></ul></li><li data-line="45"><p>NERF<br>“We represent a continuous scene as a 5D vector-valued function whose input is a 3D location x = (x, y, z) and 2D viewing direction (θ, φ), and whose output is an emitted color c = (r, g, b) and volume density σ.” (<a data-tooltip-position="top" aria-label="zotero://open-pdf/library/items/JMSMQL9S?page=4&amp;annotation=CETDTPAE" rel="noopener" class="external-link" href="zotero://open-pdf/library/items/JMSMQL9S?page=4&amp;annotation=CETDTPAE" target="_blank">pdf</a>)</p><ul><li data-line="48">“We encourage the representation to be multiview consistent by restricting the network to predict the volume density σ as a function of only the location x, while allowing the RGB color c to be predicted as a function of both location and viewing direction.” (<a data-tooltip-position="top" aria-label="zotero://open-pdf/library/items/JMSMQL9S?page=5&amp;annotation=DNZMZAYE" rel="noopener" class="external-link" href="zotero://open-pdf/library/items/JMSMQL9S?page=5&amp;annotation=DNZMZAYE" target="_blank">pdf</a>)<ul><li data-line="49">“the MLP FΘ first processes the input 3D coordinate x with 8 fully-connected layers... and outputs σ and a 256-dimensional feature vector. This feature vector is then concatenated with the camera ray’s viewing direction and passed to one additional layer... that output the view-dependent RGB color.” (<a data-tooltip-position="top" aria-label="zotero://open-pdf/library/items/JMSMQL9S?page=5&amp;annotation=3V7EPA8Y" rel="noopener" class="external-link" href="zotero://open-pdf/library/items/JMSMQL9S?page=5&amp;annotation=3V7EPA8Y" target="_blank">pdf</a>)</li></ul></li></ul></li><li data-line="51"><p>Volume rendering with radiance fields</p><ul><li data-line="52"><div alt="Pasted image 20231113215201" src="images\pasted-image-20231113215201.png" class="internal-embed media-embed image-embed is-loaded"><img alt="Pasted image 20231113215201" src="images\pasted-image-20231113215201.png"></div></li><li data-line="53">5D radiance fields (3D volumes with 2D view-dependent appearance)</li><li data-line="54">A volumetric version of <a data-tooltip-position="top" aria-label="https://grail.cs.washington.edu/projects/slf/" rel="noopener" class="external-link" href="https://grail.cs.washington.edu/projects/slf/" target="_blank">Surface Light Fields</a></li><li data-line="55">“render the color of any ray passing through the scene using principles from classical<a data-tooltip-position="top" aria-label="https://www.youtube.com/watch?v=y4KdxaMC69w" rel="noopener" class="external-link" href="https://www.youtube.com/watch?v=y4KdxaMC69w" target="_blank"> volume rendering</a> (<a data-tooltip-position="top" aria-label="zotero://open-pdf/library/items/JMSMQL9S?page=5&amp;annotation=RWSHXLPR" rel="noopener" class="external-link" href="zotero://open-pdf/library/items/JMSMQL9S?page=5&amp;annotation=RWSHXLPR" target="_blank">pdf</a>)<br><div alt="Pasted image 20231113205713" src="images\pasted-image-20231113205713.png" class="internal-embed media-embed image-embed is-loaded"><img alt="Pasted image 20231113205713" src="images\pasted-image-20231113205713.png"></div></li><li data-line="57">“We numerically estimate this continuous integral using quadrature. Deterministic quadrature, which is typically used for rendering discretized voxel grids, would effectively limit our representation’s resolution because the MLP would only be queried at a fixed discrete set of locations. Instead, we use a stratified sampling approach where we partition [tn, tf ] into N evenly-spaced bins” (<a data-tooltip-position="top" aria-label="zotero://open-pdf/library/items/JMSMQL9S?page=6&amp;annotation=7AIFY6V5" rel="noopener" class="external-link" href="zotero://open-pdf/library/items/JMSMQL9S?page=6&amp;annotation=7AIFY6V5" target="_blank">pdf</a>)</li></ul></li><li data-line="59"><p>Optimizing a nerf</p><ul><li data-line="60">Positional encoding<ul><li data-line="61">“directly operate on xyzθφ input coordinates results in renderings that perform poorly at representing high-frequency variation in color and geometry.” (<a data-tooltip-position="top" aria-label="zotero://open-pdf/library/items/JMSMQL9S?page=7&amp;annotation=V3PTPQAT" rel="noopener" class="external-link" href="zotero://open-pdf/library/items/JMSMQL9S?page=7&amp;annotation=V3PTPQAT" target="_blank">pdf</a>)</li><li data-line="62">deep networks are biased towards learning lower frequency functions.</li><li data-line="63">“positional encoding.”(<a data-tooltip-position="top" aria-label="zotero://open-pdf/library/items/JMSMQL9S?page=8&amp;annotation=FL2QIMB9" rel="noopener" class="external-link" href="zotero://open-pdf/library/items/JMSMQL9S?page=8&amp;annotation=FL2QIMB9" target="_blank">pdf</a>)<ul><li data-line="64"><div alt="Pasted image 20231113212602" src="images\pasted-image-20231113212602.png" class="internal-embed media-embed image-embed is-loaded"><img alt="Pasted image 20231113212602" src="images\pasted-image-20231113212602.png"></div></li></ul></li><li data-line="65">FΘ as a composition of two functions FΘ = F ′ Θ ◦ γ,</li></ul></li><li data-line="66">Hirarchical volume sampling<ul><li data-line="67">“hierarchical representation that increases rendering efficiency by allocating samples proportionally to their expected effect on the final rendering.” (<a data-tooltip-position="top" aria-label="zotero://open-pdf/library/items/JMSMQL9S?page=8&amp;annotation=K6YI759Q" rel="noopener" class="external-link" href="zotero://open-pdf/library/items/JMSMQL9S?page=8&amp;annotation=K6YI759Q" target="_blank">pdf</a>)</li><li data-line="68">“we simultaneously optimize two networks: one “coarse” and one “fine”. We first sample a set of Nc locations using stratified sampling, and evaluate the “coarse” network at these locations. Given the output of this “coarse” network, we then produce a more informed sampling of points along each ray where samples are biased towards the relevant parts of the volume.” (<a data-tooltip-position="top" aria-label="zotero://open-pdf/library/items/JMSMQL9S?page=8&amp;annotation=7ZTLKKKI" rel="noopener" class="external-link" href="zotero://open-pdf/library/items/JMSMQL9S?page=8&amp;annotation=7ZTLKKKI" target="_blank">pdf</a>)</li><li data-line="69"><div alt="Pasted image 20231113213137" src="images\pasted-image-20231113213137.png" class="internal-embed media-embed image-embed is-loaded"><img alt="Pasted image 20231113213137" src="images\pasted-image-20231113213137.png"></div></li></ul></li></ul></li><li data-line="71"><p>Implementation</p><ul><li data-line="72"><a data-tooltip-position="top" aria-label="https://github.com/colmap/colmap" rel="noopener" class="external-link" href="https://github.com/colmap/colmap" target="_blank">Colmap</a> for camera poses and intrinsic parameters</li><li data-line="73">Minimize the rendering error of the network with respect to the training images<ul><li data-line="74"><div width="250" alt="Pasted image 20231113215918.png" src="images\pasted-image-20231113215918.png" class="internal-embed media-embed image-embed is-loaded"><img alt="Pasted image 20231113215918.png" src="images\pasted-image-20231113215918.png" style="max-width:100%"></div></li></ul></li><li data-line="75"></li></ul></li></ul></div><div class="mod-footer"></div></div></div></div><div class="sidebar-right sidebar"><div class="sidebar-gutter"><div class="clickable-icon sidebar-collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><path d="M21 3H3C1.89543 3 1 3.89543 1 5V19C1 20.1046 1.89543 21 3 21H21C22.1046 21 23 20.1046 23 19V5C23 3.89543 22.1046 3 21 3Z"></path><path d="M10 4V20"></path><path d="M4 7H7"></path><path d="M4 10H7"></path><path d="M4 13H7"></path></svg></div></div><div class="sidebar-container"><div class="sidebar-sizer"><div class="sidebar-content-positioner"><div class="sidebar-content"><div class="graph-view-wrapper"><div class="sidebar-section-header">Interactive Graph</div><div class="graph-view-placeholder"><div class="graph-view-container"><div class="graph-icon graph-expand" role="button" aria-label="Expand" data-tooltip-position="top"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><line x1="7" y1="17" x2="17" y2="7"></line><polyline points="7 7 17 7 17 17"></polyline></svg></div><canvas id="graph-canvas" width="512px" height="512px"></canvas></div></div></div><div class="tree-container outline-tree" data-depth="0"><div class="tree-header"><span class="sidebar-section-header">Table Of Contents</span><button class="clickable-icon collapse-tree-button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></svg></button></div><div class="tree-scroll-area"></div></div></div></div></div></div></div></div></body></html>